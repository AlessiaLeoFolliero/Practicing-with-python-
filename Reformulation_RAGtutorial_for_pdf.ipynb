{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrHQhj/l7q+Gq4a1wZwLbP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlessiaLeoFolliero/Practicing-with-python-/blob/main/Reformulation_RAGtutorial_for_pdf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://realpython.com/build-llm-rag-chatbot-with-langchain/"
      ],
      "metadata": {
        "id": "sWrMB6Ah9Y38"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bl0rdCyI9RFk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import (\n",
        "    PromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    ChatPromptTemplate,\n",
        ")\n",
        "\n",
        "# Load PDFs\n",
        "loader = PyPDFLoader(\"hospital_reviews.pdf\")  # Path to your PDF file\n",
        "documents = loader.load()\n",
        "\n",
        "# Chunk the text\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,  # Maximum characters per chunk\n",
        "    chunk_overlap=50,  # Overlap between chunks\n",
        ")\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "# Create vector index using FAISS\n",
        "faiss_index = FAISS.from_documents(docs, OpenAIEmbeddings())\n",
        "\n",
        "# Define prompts\n",
        "review_template = \"\"\"Your job is to use patient\n",
        "reviews to answer questions about their experience at a hospital. Use\n",
        "the following context to answer questions. Be as detailed as possible, but\n",
        "don't make up any information that's not from the context. If you don't know\n",
        "an answer, say you don't know.\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "review_system_prompt = SystemMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(input_variables=[\"context\"], template=review_template)\n",
        ")\n",
        "\n",
        "review_human_prompt = HumanMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(input_variables=[\"question\"], template=\"{question}\")\n",
        ")\n",
        "messages = [review_system_prompt, review_human_prompt]\n",
        "\n",
        "review_prompt = ChatPromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"], messages=messages\n",
        ")\n",
        "\n",
        "# Create RetrievalQA chain\n",
        "reviews_pdf_chain = RetrievalQA.from_chain_type(\n",
        "    llm=ChatOpenAI(model=\"gpt-4\", temperature=0),\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=faiss_index.as_retriever(k=10),\n",
        ")\n",
        "reviews_pdf_chain.combine_documents_chain.llm_chain.prompt = review_prompt\n",
        "\n",
        "# Example question\n",
        "question = \"What do patients say about their experience with Dr. Smith?\"\n",
        "response = reviews_pdf_chain.run(question)\n",
        "print(response)\n"
      ]
    }
  ]
}